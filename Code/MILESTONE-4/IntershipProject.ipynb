{"cells":[{"cell_type":"markdown","source":["#**Srinivas**\n","\n","#srinivasacademics@gmail.com\n"],"metadata":{"id":"8EpdzKGoNKgQ"},"id":"8EpdzKGoNKgQ"},{"cell_type":"markdown","source":["# Install all necessary libraries\n","\n"],"metadata":{"id":"lyP1BlZ7ZG9e"},"id":"lyP1BlZ7ZG9e"},{"cell_type":"code","source":["\n","!pip install -q streamlit pyngrok transformers torch sentence-transformers textblob scikit-learn"],"metadata":{"id":"wjZ65z74JwtY","executionInfo":{"status":"ok","timestamp":1762251871369,"user_tz":-330,"elapsed":11437,"user":{"displayName":"SRINIVAS","userId":"10177738441441990874"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e00cacc-5447-446d-bd21-fb55d456feeb"},"id":"wjZ65z74JwtY","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/10.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/10.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m9.4/10.2 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m270.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m143.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["# Paste NGROK Token\n"],"metadata":{"id":"acwfJcryZT6W"},"id":"acwfJcryZT6W"},{"cell_type":"code","source":["from pyngrok import ngrok\n","\n","# Paste your Ngrok authentication token here\n","NGROK_AUTH_TOKEN = \"34F6Q8gRoCiwig6coEfg5NNhS8b_4AX2tBzeukTEgwJ27gJgS\"\n","ngrok.set_auth_token(NGROK_AUTH_TOKEN)"],"metadata":{"id":"AcsIwwfhJyMA","executionInfo":{"status":"ok","timestamp":1762251872658,"user_tz":-330,"elapsed":1283,"user":{"displayName":"SRINIVAS","userId":"10177738441441990874"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75e2b8b0-c3c1-4129-ed9b-9f19ecab20c2"},"id":"AcsIwwfhJyMA","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"markdown","source":["#Code"],"metadata":{"id":"vnw8QyGAZrkl"},"id":"vnw8QyGAZrkl"},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import time\n","import sqlite3\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from multiprocessing import Pool, cpu_count\n","from transformers import pipeline\n","from textblob import TextBlob\n","import smtplib\n","from email.mime.multipart import MIMEMultipart\n","from email.mime.text import MIMEText\n","from email.mime.application import MIMEApplication\n","import os\n","\n","# --- Caching for Model Loading ---\n","@st.cache_resource # Decorator to cache the loaded model across runs\n","def load_sentiment_pipeline():\n","    \"\"\"Loads and caches the Hugging Face sentiment analysis pipeline.\"\"\"\n","    print(\"LOG: Caching and loading the sentiment pipeline model for the first time.\")\n","    # Load the pre-trained model for sentiment analysis from Hugging Face\n","    return pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\", device=-1) # Use CPU\n","\n","# --- Analysis Functions ---\n","def run_sequential_analysis(texts, pipeline_model):\n","    \"\"\"Performs sentiment analysis item by item using a single core.\"\"\"\n","    print(\"\\nLOG: --- Starting SEQUENTIAL Analysis ---\")\n","    start_time = time.time() # Record start time\n","    results = [] # List to store analysis results (label, score)\n","    # Use st.status for better UI feedback during long operations\n","    with st.status(\"Running sequential analysis...\") as status_seq:\n","        # Loop through each text entry\n","        for i, text in enumerate(texts):\n","            result = pipeline_model(text, truncation=True)[0] # Run model prediction\n","            results.append((result['label'].capitalize(), result['score'])) # Store label and score\n","            # Update the status message in the UI\n","            status_seq.update(label=f\"Sequential: Processing item {i+1}/{len(texts)}...\")\n","    processing_time = time.time() - start_time # Calculate total time\n","    print(f\"LOG: --- Sequential analysis finished in {processing_time:.2f} seconds. ---\")\n","    # Separate labels and scores for easier use later\n","    labels = [res[0] for res in results]\n","    scores = [res[1] for res in results]\n","    return labels, scores, processing_time\n","\n","def process_chunk(text_chunk):\n","    \"\"\"Worker function for parallel processing: analyzes a subset (chunk) of data.\"\"\"\n","    pid = os.getpid() # Get the unique process ID for logging\n","    print(f\"LOG: Parallel worker process started with ID: {pid}\")\n","    # Each parallel worker needs to load its own instance of the pipeline\n","    sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\", device=-1)\n","    # Analyze the assigned chunk of text; batch_size improves efficiency\n","    results = sentiment_pipeline(list(text_chunk), batch_size=8, truncation=True)\n","    print(f\"LOG: Parallel worker {pid} finished its chunk.\")\n","    # Return list of tuples (label, score) for this chunk\n","    return [(res['label'].capitalize(), res['score']) for res in results]\n","\n","def run_parallel_analysis(texts):\n","    \"\"\"Performs sentiment analysis using multiple CPU cores simultaneously.\"\"\"\n","    print(\"\\nLOG: --- Starting PARALLEL Analysis ---\")\n","    num_cores = cpu_count() # Detect the number of available CPU cores\n","    print(f\"LOG: Creating a pool of {num_cores} worker processes.\")\n","    start_time = time.time()\n","    # Split the list of texts into roughly equal chunks for each core\n","    text_chunks = np.array_split(texts, num_cores)\n","    # Create a pool of worker processes\n","    with Pool(num_cores) as pool:\n","        # Distribute the chunks to the workers and collect results\n","        # pool.map automatically handles distributing data and gathering results\n","        chunk_results = pool.map(process_chunk, text_chunks)\n","    processing_time = time.time() - start_time\n","    print(f\"LOG: --- Parallel analysis finished in {processing_time:.2f} seconds. ---\")\n","    # Combine results from all chunks into a single list\n","    combined_results = [item for sublist in chunk_results for item in sublist]\n","    # Separate labels and scores\n","    labels = [res[0] for res in combined_results]\n","    scores = [res[1] for res in combined_results]\n","    return labels, scores, processing_time, num_cores\n","\n","def get_textblob_details(text):\n","    \"\"\"Analyzes text polarity (sentiment) and subjectivity using TextBlob.\"\"\"\n","    sentiment = TextBlob(str(text)).sentiment # Ensure input is string, get sentiment object\n","    polarity = sentiment.polarity # Score from -1.0 (negative) to +1.0 (positive)\n","    subjectivity = sentiment.subjectivity # Score from 0.0 (objective) to 1.0 (subjective)\n","    # Classify sentiment label based on polarity score thresholds\n","    if polarity > 0.05: sentiment_label = \"Positive\"\n","    elif polarity < -0.05: sentiment_label = \"Negative\"\n","    else: sentiment_label = \"Neutral\" # Create a 'neutral zone' around 0\n","    # Return both results as a pandas Series for easy assignment to DataFrame columns\n","    return pd.Series([sentiment_label, subjectivity])\n","\n","# --- Streamlit User Interface ---\n","st.set_page_config(layout=\"wide\") # Use the full browser width for the app\n","st.title(\"Sentiment Analysis Application\") # Main title displayed at the top\n","\n","# --- Quick Analysis Section ---\n","# Allows users to test a single piece of text without uploading a file\n","st.header(\"Quick Analysis\")\n","with st.container(border=True): # Visually group this section\n","    quick_text = st.text_area(\"Enter text for instant analysis:\", height=100) # Input box\n","    if st.button(\"Analyze Single Text\"): # Button to trigger analysis\n","        if quick_text:\n","            with st.spinner(\"Loading model and analyzing...\"): # Show loading indicator\n","                model = load_sentiment_pipeline() # Load the LLM (cached)\n","                prediction = model(quick_text, truncation=True)[0] # Get prediction\n","                label = prediction['label'].capitalize()\n","                score = prediction['score']\n","            # Display the result using st.metric for nice formatting\n","            st.metric(label=f\"**LLM Sentiment: {label}**\", value=f\"{score:.1%}\")\n","            st.caption(\"Result from the Hugging Face LLM model.\") # Clarify model source\n","        else:\n","            st.warning(\"Please enter some text to analyze.\") # Handle empty input\n","st.markdown(\"<br>\", unsafe_allow_html=True) # Add some vertical spacing\n","\n","# --- Sidebar Configuration ---\n","# Sidebar is used for controls that affect the main analysis\n","st.sidebar.header(\"Batch Analysis Configuration\")\n","# File uploader widget allows drag-and-drop or browsing\n","uploaded_file = st.sidebar.file_uploader(\"Upload Data File (.csv or .xlsx)\", type=[\"csv\", \"xlsx\"])\n","\n","# Initialize variables in Streamlit's session state\n","# Session state keeps variables persistent across user interactions (button clicks, etc.)\n","if 'results_df' not in st.session_state: st.session_state.results_df = None # To store analysis results DataFrame\n","if 'performance' not in st.session_state: st.session_state.performance = None # To store timing metrics\n","if 'db_saved' not in st.session_state: st.session_state.db_saved = False # Flag for DB download button\n","if 'db_name' not in st.session_state: st.session_state.db_name = \"sentiment_results.db\" # Default DB filename\n","\n","# --- Data Loading and Batch Analysis Setup ---\n","# This block only runs if a file has been uploaded\n","if uploaded_file:\n","    try:\n","        # Read the uploaded file into a pandas DataFrame based on its extension\n","        df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith('.csv') else pd.read_excel(uploaded_file)\n","        # Dropdown menu for the user to select the column containing text\n","        text_column = st.sidebar.selectbox(\"Select Text Column:\", df.columns)\n","        # Remove rows where the selected text column is empty before proceeding\n","        df_cleaned = df.dropna(subset=[text_column]).copy()\n","\n","        # --- Row Selection Widgets ---\n","        st.sidebar.markdown(\"---\") # Visual separator\n","        st.sidebar.write(\"**Select Number of Rows**\")\n","        # Slider for quick, approximate selection\n","        slider_val = st.sidebar.slider(\"Drag\", 10, len(df_cleaned), min(100, len(df_cleaned)), 10, label_visibility=\"collapsed\")\n","        # Number input for precise entry, linked to the slider's value\n","        num_rows = st.sidebar.number_input(\"Enter number\", 10, len(df_cleaned), slider_val, 10)\n","        st.sidebar.markdown(\"---\")\n","\n","        # Create the sample DataFrame based on the selected number of rows\n","        df_sample = df_cleaned.head(num_rows)\n","        # Extract the text data into a list for efficient processing by analysis functions\n","        texts = df_sample[text_column].tolist()\n","\n","        # --- Analysis Execution Trigger ---\n","        # This code runs only when the \"Run Batch Analysis\" button is clicked\n","        if st.sidebar.button(\"Run Batch Analysis\"):\n","            # Use st.status for displaying sequential steps clearly\n","            with st.status(\"Starting Analysis...\", expanded=True) as status_main:\n","                status_main.update(label=\"Step 1/3: Loading sentiment model...\")\n","                sentiment_pipeline = load_sentiment_pipeline() # Load or get the cached LLM\n","\n","                status_main.update(label=\"Step 2/3: Running sequential analysis...\")\n","                sequential_labels, sequential_scores, seq_time = run_sequential_analysis(texts, sentiment_pipeline)\n","                df_sample['LLM Sentiment'] = sequential_labels # Add results to the sample DataFrame\n","                df_sample['LLM Confidence'] = sequential_scores\n","\n","                status_main.update(label=f\"Step 3/3: Preparing parallel analysis...\")\n","                # Use st.spinner for the parallel part as granular progress is harder to track\n","                with st.spinner(f\"Running parallel analysis using {cpu_count()} cores...\"):\n","                     parallel_labels, parallel_scores, par_time, num_cores = run_parallel_analysis(texts)\n","                # Note: We assume parallel is correct if sequential worked, primarily using it for timing.\n","\n","                # Run TextBlob analysis on the text column\n","                df_sample[['TextBlob Sentiment', 'TextBlob Subjectivity']] = df_sample[text_column].apply(get_textblob_details)\n","\n","                status_main.update(label=\"Analysis Complete!\", state=\"complete\", expanded=False) # Collapse status box on completion\n","\n","            # Prepare DataFrames for the Execution Proof section\n","            seq_proof_df = pd.DataFrame({'Text': texts[:5], 'LLM Sentiment': sequential_labels[:5], 'LLM Confidence': sequential_scores[:5]})\n","            par_proof_df = pd.DataFrame({'Text': texts[:5], 'LLM Sentiment': parallel_labels[:5], 'LLM Confidence': parallel_scores[:5]})\n","\n","            # Store results and performance metrics in session state to display them\n","            st.session_state.results_df = df_sample.copy()\n","            st.session_state.performance = {\n","                \"sequential_time\": seq_time, \"parallel_time\": par_time,\n","                \"num_cores\": num_cores, \"text_column\": text_column, # Store selected column name\n","                \"sequential_proof\": seq_proof_df, \"parallel_proof\": par_proof_df\n","            }\n","            st.session_state.db_saved = False # Reset DB flag as new results are generated\n","\n","    except Exception as e:\n","        # Show error message if file loading/processing fails\n","        st.error(f\"Error processing file: {e}\")\n","else:\n","    # Message shown when the app starts, before a file is uploaded\n","    st.info(\"Upload a data file to run batch analysis.\")\n","\n","# --- Main Panel for Displaying Batch Results ---\n","# This block runs only after analysis is complete (results_df exists in session state)\n","if st.session_state.results_df is not None:\n","    results_df = st.session_state.results_df\n","    performance = st.session_state.performance\n","\n","    # --- Section 1: Performance ---\n","    st.header(\"Batch Performance Metrics\")\n","    with st.container(border=True): # Visual grouping\n","        # Display timing and speedup using st.metric\n","        col1, col2, col3 = st.columns(3)\n","        col1.metric(\"Sequential Time\", f\"{performance['sequential_time']:.2f} s\")\n","        col2.metric(f\"Parallel Time ({performance['num_cores']} Cores)\", f\"{performance['parallel_time']:.2f} s\")\n","        speedup = performance['sequential_time'] / performance['parallel_time'] if performance['parallel_time'] > 0 else 0\n","        col3.metric(\"Speedup Factor\", f\"{speedup:.2f}x\")\n","\n","        # Expandable section with notes explaining performance differences\n","        with st.expander(\"Performance Notes\"):\n","             st.markdown(\"\"\"\n","             **Understanding Sequential vs. Parallel Speed:**\n","             1.  **Overhead:** Parallel processing involves starting multiple independent processes, which has a time cost.\n","             2.  **Model Loading:** *Each* parallel process needs to load the ~501MB sentiment model into RAM separately, consuming time and memory (Total RAM ≈ 501MB × Cores). Sequential loads it only once.\n","             3.  **Small Datasets:** For fewer items (< ~200), the overhead and separate model loading often make parallel *slower* than sequential.\n","             4.  **Large Datasets:** For more items (500+), the time saved by analyzing simultaneously outweighs the setup cost, making parallel significantly faster (often 2-3x+).\n","             5.  **Conclusion:** Parallelism is beneficial for large tasks but adds overhead that's noticeable on small tasks.\n","             \"\"\")\n","\n","        # Expandable section showing first 5 results from both methods as proof\n","        with st.expander(\"Execution Proof (First 5 Results)\"):\n","            col_proof1, col_proof2 = st.columns(2)\n","            # Format confidence scores as percentages for display\n","            proof_seq_formatted = performance['sequential_proof'].copy()\n","            proof_seq_formatted['LLM Confidence'] = proof_seq_formatted['LLM Confidence'].map('{:.1%}'.format)\n","            proof_par_formatted = performance['parallel_proof'].copy()\n","            proof_par_formatted['LLM Confidence'] = proof_par_formatted['LLM Confidence'].map('{:.1%}'.format)\n","            with col_proof1:\n","                st.subheader(\"Sequential LLM\")\n","                st.table(proof_seq_formatted) # Use st.table for simple data display\n","            with col_proof2:\n","                st.subheader(\"Parallel LLM\")\n","                st.table(proof_par_formatted)\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True) # Add vertical space\n","\n","    # --- Section 2: Analysis & Comparison ---\n","    st.header(\"Batch Analysis Results\")\n","    with st.container(border=True):\n","        # Checkboxes to allow users to toggle graph visibility\n","        st.write(\"**Select Visualizations to Display:**\")\n","        show_heatmap = st.checkbox(\"Agreement Heatmap\", value=True)\n","        show_distribution_bar = st.checkbox(\"Distribution Bar Chart\", value=True)\n","        show_distribution_pie = st.checkbox(\"Distribution Pie Chart\", value=False)\n","        show_disagreement_bar = st.checkbox(\"Disagreement Bar Chart\", value=False)\n","        st.markdown(\"---\")\n","\n","        # Arrange comparison charts/info in columns\n","        col_left, col_right = st.columns([0.6, 0.4]) # Give more space to the left column\n","\n","        with col_left: # Agreement analysis and disagreement examples\n","            if show_heatmap:\n","                st.subheader(\"Model Agreement Heatmap\")\n","                # Calculate how often LLM and TextBlob results match\n","                comparison_matrix = pd.crosstab(results_df['TextBlob Sentiment'], results_df['LLM Sentiment'])\n","                # Plot using seaborn's heatmap\n","                fig1, ax1 = plt.subplots(figsize=(5, 3.5))\n","                sns.heatmap(comparison_matrix, annot=True, fmt='d', cmap='Blues', ax=ax1)\n","                ax1.set_ylabel('TextBlob')\n","                ax1.set_xlabel('LLM')\n","                st.pyplot(fig1, use_container_width=True) # Display the plot\n","\n","            # Find rows where the sentiment predictions differ\n","            disagreements = results_df[results_df['TextBlob Sentiment'] != results_df['LLM Sentiment']]\n","            if not disagreements.empty:\n","                text_col_name = performance['text_column'] # Get original text column name\n","                # Show specific disagreement examples in an expander\n","                with st.expander(f\"Disagreement Examples ({len(disagreements)} total)\"):\n","                    st.caption(\"Subjectivity Score (Subj): 0.0=Fact, 1.0=Opinion.\") # Add explanation here\n","                    for i, row in disagreements.head(5).iterrows():\n","                        st.markdown(f\"**Text:** *'{row[text_col_name][:100]}...'*\\n\"\n","                                    f\"- TextBlob: `{row['TextBlob Sentiment']}` (Subj: {row['TextBlob Subjectivity']:.2f})\\n\"\n","                                    f\"- LLM: `{row['LLM Sentiment']}` (Conf: {row['LLM Confidence']:.1%})\")\n","                        st.markdown(\"---\")\n","\n","            # Optional bar chart showing disagreements\n","            if show_disagreement_bar and not disagreements.empty:\n","                 st.subheader(\"Disagreements by LLM Sentiment\")\n","                 # Count how many disagreements fall into each LLM sentiment category\n","                 disagreement_counts = disagreements['LLM Sentiment'].value_counts()\n","                 fig_dis, ax_dis = plt.subplots(figsize=(5, 3.5))\n","                 disagreement_counts.plot(kind='bar', ax=ax_dis, color=['lightcoral', 'lightskyblue', 'lightgrey'])\n","                 ax_dis.set_ylabel('Number of Disagreements')\n","                 ax_dis.set_xlabel('LLM Prediction (when TextBlob differed)')\n","                 ax_dis.tick_params(axis='x', rotation=0)\n","                 st.pyplot(fig_dis, use_container_width=True)\n","            elif show_disagreement_bar and disagreements.empty:\n","                 st.caption(\"No disagreements found to plot.\")\n","\n","\n","        with col_right: # Sentiment distribution charts\n","            st.subheader(\"LLM Sentiment Distribution\")\n","            # Calculate counts and percentages for each sentiment\n","            sentiment_counts = results_df['LLM Sentiment'].value_counts()\n","            total_count = len(results_df)\n","            perc_pos = (sentiment_counts.get(\"Positive\", 0) / total_count) * 100\n","            perc_neg = (sentiment_counts.get(\"Negative\", 0) / total_count) * 100\n","            perc_neu = (sentiment_counts.get(\"Neutral\", 0) / total_count) * 100\n","            # Display percentages using st.metric\n","            met_col1, met_col2, met_col3 = st.columns(3)\n","            met_col1.metric(\"Positive\", f\"{perc_pos:.1f}%\")\n","            met_col2.metric(\"Negative\", f\"{perc_neg:.1f}%\")\n","            met_col3.metric(\"Neutral\", f\"{perc_neu:.1f}%\")\n","\n","            # Optional bar chart\n","            if show_distribution_bar:\n","                st.markdown(\"###### Distribution Bar Chart\")\n","                fig2, ax2 = plt.subplots(figsize=(5, 3))\n","                sentiment_counts.plot(kind='bar', ax=ax2, color=['skyblue', 'salmon', 'lightgray'])\n","                ax2.set_ylabel('Count')\n","                ax2.tick_params(axis='x', rotation=0)\n","                st.pyplot(fig2, use_container_width=True)\n","\n","            # Optional pie chart\n","            if show_distribution_pie:\n","                st.markdown(\"###### Distribution Pie Chart\")\n","                colors = {'Positive': 'skyblue', 'Negative': 'salmon', 'Neutral': 'lightgray'}\n","                chart_colors = [colors.get(sentiment, '#CCCCCC') for sentiment in sentiment_counts.index]\n","                fig3, ax3 = plt.subplots(figsize=(5, 3))\n","                # Explode smallest slice slightly for better visibility\n","                explode = tuple([0.05 if x == sentiment_counts.min() else 0 for x in sentiment_counts])\n","                ax3.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=chart_colors, explode=explode)\n","                ax3.axis('equal') # Ensures pie chart is circular\n","                st.pyplot(fig3, use_container_width=True)\n","\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # --- Section 3: Detailed Data Table ---\n","    st.header(\"Detailed Results Table\")\n","    with st.container(border=True):\n","        # Explanation moved to Disagreement Expander above, keeping table clean\n","        # st.caption(\"Subjectivity Score (TextBlob): 0.0 (Objective) to 1.0 (Subjective).\")\n","        st.caption(\"\"\"\n","        **Subjectivity Score (TextBlob):** Measures how opinionated the text is vs. factual.\n","        Ranges from **0.0 (Objective - likely a fact)** to **1.0 (Subjective - likely an opinion)**.\n","        \"\"\")\n","        st.subheader(\"Filter Displayed Data\")\n","        # Add filter widgets (multiselect for sentiment, checkbox for disagreements)\n","        col_filter1, col_filter2 = st.columns(2)\n","        with col_filter1:\n","            filter_sentiment = st.multiselect(\"Filter by LLM Sentiment:\", results_df['LLM Sentiment'].unique(), default=results_df['LLM Sentiment'].unique())\n","        with col_filter2:\n","             show_disagreements_only = st.checkbox(\"Show only disagreements\")\n","\n","        # Apply selected filters to the results DataFrame\n","        filtered_df = results_df[results_df['LLM Sentiment'].isin(filter_sentiment)]\n","        if show_disagreements_only:\n","            filtered_df = filtered_df[filtered_df['LLM Sentiment'] != filtered_df['TextBlob Sentiment']]\n","\n","        st.write(f\"Displaying {len(filtered_df)} of {len(results_df)} results.\")\n","        # Select and format specific columns for the main table display\n","        text_col_name = performance['text_column']\n","        cols_to_display = [text_col_name, 'LLM Sentiment', 'LLM Confidence', 'TextBlob Sentiment', 'TextBlob Subjectivity']\n","        cols_exist = [col for col in cols_to_display if col in filtered_df.columns]\n","        display_df_filtered_cols = filtered_df[cols_exist].copy()\n","\n","        # Format confidence and subjectivity for display\n","        if 'LLM Confidence' in display_df_filtered_cols:\n","             display_df_filtered_cols['LLM Confidence'] = display_df_filtered_cols['LLM Confidence'].map('{:.1%}'.format)\n","        if 'TextBlob Subjectivity' in display_df_filtered_cols:\n","             display_df_filtered_cols['TextBlob Subjectivity'] = display_df_filtered_cols['TextBlob Subjectivity'].map('{:.2f}'.format)\n","\n","        # Rename original text column if it's not one of the standard names\n","        if text_col_name not in ['LLM Sentiment', 'LLM Confidence', 'TextBlob Sentiment', 'TextBlob Subjectivity']:\n","             display_df_filtered_cols = display_df_filtered_cols.rename(columns={text_col_name: \"Original Text\"})\n","\n","        # Display the final, filtered, formatted table\n","        st.dataframe(display_df_filtered_cols)\n","\n","    st.markdown(\"<br>\", unsafe_allow_html=True)\n","\n","    # --- Section 4: Save and Export ---\n","    st.header(\"Save and Export Results\")\n","    with st.container(border=True):\n","        text_col_name = performance['text_column']\n","        # Prepare the DataFrame for export (consistent columns)\n","        cols_to_export = [text_col_name, 'LLM Sentiment', 'LLM Confidence', 'TextBlob Sentiment', 'TextBlob Subjectivity']\n","        cols_exist_export = [col for col in cols_to_export if col in results_df.columns]\n","        final_export_df = results_df[cols_exist_export].rename(columns={\n","            text_col_name: \"Original Text\" # Standardize text column name for export\n","        })\n","\n","        # Arrange export options in columns\n","        col_db, col_csv, col_email = st.columns(3)\n","\n","        # Database Save/Download controls\n","        with col_db:\n","            st.subheader(\"Database\")\n","            db_name_input = st.text_input(\"DB file name (.db)\", value=st.session_state.db_name, key=\"db_name_input\")\n","            # Update DB name if user changes it\n","            if db_name_input != st.session_state.db_name:\n","                 st.session_state.db_name = db_name_input\n","                 st.session_state.db_saved = False # Must re-save if name changed\n","            # Button to save data to SQLite\n","            if st.button(\"Save to DB\"):\n","                try:\n","                    conn = sqlite3.connect(st.session_state.db_name)\n","                    # Write the final_export_df to the specified table\n","                    final_export_df.to_sql(\"sentiment_results\", conn, if_exists=\"replace\", index=False)\n","                    conn.close()\n","                    st.session_state.db_saved = True # Mark as saved\n","                    st.success(f\"Saved to `{st.session_state.db_name}`.\")\n","                except Exception as e: st.error(f\"DB Error: {e}\"); st.session_state.db_saved = False\n","            # Show download button only after successful save\n","            if st.session_state.db_saved:\n","                try:\n","                    # Read the saved file in binary mode\n","                    with open(st.session_state.db_name, \"rb\") as fp:\n","                        st.download_button(label=\"Download DB File\", data=fp, file_name=st.session_state.db_name, mime=\"application/octet-stream\")\n","                except FileNotFoundError: st.error(f\"DB file not found.\")\n","                except Exception as e: st.error(f\"Error reading DB file: {e}\")\n","\n","        # CSV Download controls\n","        with col_csv:\n","            st.subheader(\"CSV File\")\n","            csv_filename = st.text_input(\"CSV file name\", \"sentiment_analysis_results.csv\")\n","            # Convert DataFrame to CSV bytes\n","            csv_data = final_export_df.to_csv(index=False).encode('utf-8')\n","            st.download_button(\"Download CSV\", csv_data, csv_filename, 'text/csv')\n","\n","        # Email Report controls\n","        with col_email:\n","            st.subheader(\"Email Report\")\n","            recipient_email = st.text_input(\"Recipient Email\", placeholder=\"Enter recipient email ID\") # Email input\n","            if st.button(\"Send Email\"): # Button to send\n","                if not recipient_email: st.warning(\"Enter recipient email.\")\n","                else:\n","                    try:\n","                        # Build email message\n","                        msg = MIMEMultipart()\n","                        msg['Subject'] = \"Sentiment Analysis Report\"\n","                        msg['From'] = \"websitehosting0123@gmail.com\" # Sender email\n","                        msg['To'] = recipient_email\n","                        msg.attach(MIMEText(\"Sentiment analysis results attached.\", 'plain')) # Email body\n","                        # Attach the CSV data\n","                        part = MIMEApplication(final_export_df.to_csv(index=False).encode('utf-8'), Name=csv_filename)\n","                        part['Content-Disposition'] = f'attachment; filename=\"{csv_filename}\"'\n","                        msg.attach(part)\n","                        # --- Email Sending Logic ---\n","                        # IMPORTANT: Use a Gmail App Password here for security\n","                        app_password = \"tzfheimxphcssuag\" # Replace with your 16-digit app password\n","                        # Connect to Gmail's SSL SMTP server\n","                        with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:\n","                            server.login(msg['From'], app_password) # Login\n","                            server.sendmail(msg['From'], [msg['To']], msg.as_string()) # Send\n","                        st.success(f\"Email sent to {recipient_email}!\")\n","                    except Exception as e: st.error(f\"Email Error: {e}\") # Show errors"],"metadata":{"id":"3ugAnEpjJ1pI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762251872801,"user_tz":-330,"elapsed":146,"user":{"displayName":"SRINIVAS","userId":"10177738441441990874"}},"outputId":"c1b63c35-818b-43fb-9216-c9ed9f8ae635"},"id":"3ugAnEpjJ1pI","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}]},{"cell_type":"markdown","source":["#New Tunnel for getting Public URL"],"metadata":{"id":"b92TVDPgav6K"},"id":"b92TVDPgav6K"},{"cell_type":"code","source":["import time\n","from pyngrok import ngrok\n","\n","# Clean up old logs\n","!rm -f nohup.out\n","\n","# Start Streamlit app\n","!nohup streamlit run app.py &\n","\n","# Wait for the app to start\n","time.sleep(10)\n","\n","# Kill any existing ngrok tunnels\n","ngrok.kill()\n","\n","# Start a new tunnel\n","public_url = ngrok.connect(addr=8501, proto=\"http\")\n","print(f\"Click the following link to view your app: {public_url}\")\n"],"metadata":{"id":"3bbxQNB3J4UK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762251883623,"user_tz":-330,"elapsed":10824,"user":{"displayName":"SRINIVAS","userId":"10177738441441990874"}},"outputId":"f3646a85-86cd-46cd-fd41-7829a62b26b8"},"id":"3bbxQNB3J4UK","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n","Click the following link to view your app: NgrokTunnel: \"https://silklike-dashingly-matt.ngrok-free.dev\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"code","source":["# Display the contents of the nohup.out log file\n","!cat nohup.out"],"metadata":{"id":"kpUT1U0HJ5nQ","executionInfo":{"status":"ok","timestamp":1762251883914,"user_tz":-330,"elapsed":287,"user":{"displayName":"SRINIVAS","userId":"10177738441441990874"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"39a05018-a2b6-4ed7-fab8-9cdb192e0c1b"},"id":"kpUT1U0HJ5nQ","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\n","\n","  You can now view your Streamlit app in your browser.\n","\n","  Local URL: http://localhost:8501\n","  Network URL: http://172.28.0.12:8501\n","  External URL: http://34.16.173.96:8501\n","\n"]}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}